---
sidebar: auto
next: /config/cop
---

# æŒ‡å—


## ä»‹ç» ğŸ“˜

> Pythonç”±è·å…°æ•°å­¦å’Œè®¡ç®—æœºç§‘å­¦ç ”ç©¶å­¦ä¼šçš„å‰å¤šÂ·èŒƒç½—è‹å§† äº1990 å¹´ä»£åˆè®¾è®¡ï¼Œä½œä¸ºä¸€é—¨å«åšABCè¯­è¨€çš„æ›¿ä»£å“ã€‚ Pythonæä¾›äº†é«˜æ•ˆçš„é«˜çº§æ•°æ®ç»“æ„ï¼Œè¿˜èƒ½ç®€å•æœ‰æ•ˆåœ°é¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚Pythonè¯­æ³•å’ŒåŠ¨æ€ç±»å‹ï¼Œä»¥åŠè§£é‡Šå‹è¯­è¨€çš„æœ¬è´¨ï¼Œä½¿å®ƒæˆä¸ºå¤šæ•°å¹³å°ä¸Šå†™è„šæœ¬å’Œå¿«é€Ÿå¼€å‘åº”ç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼Œéšç€ç‰ˆæœ¬çš„ä¸æ–­æ›´æ–°å’Œè¯­è¨€æ–°åŠŸèƒ½çš„æ·»åŠ ï¼Œé€æ¸è¢«ç”¨äºç‹¬ç«‹çš„ã€å¤§å‹é¡¹ç›®çš„å¼€å‘ã€‚

![å­¦ä¹ Python](./assets/python-logo-master-v3-TM.png)

å­¦ä¹  Python.


## å®‰è£… ğŸ”©

ç•¥ã€‚

## ä¾èµ–ç¯å¢ƒç­‰ ğŸ•¹ï¸

ç•¥ã€‚

## ä½¿ç”¨ ğŸ”˜

æŒæ¡å°šä¸å®Œå…¨ï¼Œæ­¤å¤„è¿˜ä¸ä¼šæ¢³ç†ç›®å½•æ¶æ„ï¼Œæƒ³åˆ°å“ªå†™åˆ°å“ªã€‚

### sys.stdout = file æ—¥å¿—è®°å½• ğŸ““

Python æ ‡å‡†è¾“å‡º `sys.stdout` é‡å®šå‘ ï¼ˆ*ä»æ§åˆ¶å°é‡å®šå‘åˆ°æ–‡ä»¶*ï¼‰

åŸå§‹çš„ sys.stdout æŒ‡å‘æ§åˆ¶å°ï¼Œå¦‚æœæŠŠæ–‡ä»¶çš„å¯¹è±¡çš„å¼•ç”¨èµ‹ç»™ `sys.stdout`ï¼Œé‚£ä¹ˆ `print` è°ƒç”¨çš„å°±æ˜¯æ–‡ä»¶å¯¹è±¡çš„ `write` æ–¹æ³•ï¼š

```python
import os
import sys

f_handler=open('out.log', 'w')
sys.stdout=f_handler
print 'hello' 
# è¿™ä¸ª hello ä¸èƒ½åœ¨æ§åˆ¶å°æŸ¥çœ‹
# è¿™ä¸ª hello åœ¨æ–‡ä»¶ out.log ä¸­
```

### æ—¶é—´æˆ³ ğŸ•¡ï¸

```python
from datetime import datetime

# ç°åœ¨æ—¶é—´-æ ¼å¼åŒ–
datetime.now().strftime('%Y-%m-%d-%H:%M:%S')
# æ‰“å°ç°åœ¨æ—¶é—´
print(datetime.now())
```

### ç›®å½•æœ‰æ— åˆ¤æ–­åŠæ–°å»º ğŸ“‡
```python
import os

# åˆ¤æ–­æœ‰æ— 
if not os.path.exists(save_dir):
  # æ–°å»ºç›®å½•
  os.makedirs(save_dir)
```

### argparse å‚æ•°ä¼ å…¥ âš™ï¸
```python
import argparse

parser = argparse.ArgumentParser(description='Python')
parser.add_argument('-sd', '--save-dir', default='./results', help='path to save')
args = parser.parse_args()
  
main(args)
```

### å¤šå¡è®­ç»ƒ ğŸ–¥ğŸ–¥ğŸ–¥ğŸ–¥

`torch.nn.DataParallel`å¤šå¡è®­ç»ƒï¼Œå¯èƒ½ä¼šå½±å“æ€§èƒ½å’Œå¯å¤ç°æ€§ï¼Œè°¨æ…ä½¿ç”¨ã€‚

```python
# torch.nn.DataParallel
device_ids = [0, 1]
net = torch.nn.DataParallel(net, device_ids=device_ids)
```
[å‚è€ƒ1:çŸ¥ä¹](https://zhuanlan.zhihu.com/p/102697821)

[å‚è€ƒ2:é—®é¢˜](https://www.zhihu.com/pin/1324807219972300800)

### TorchåŠ é€Ÿè®­ç»ƒGPU â©ï¸

`torch.backends.cudnn.benchmark = True`å°†ä¼šè®©ç¨‹åºåœ¨å¼€å§‹æ—¶èŠ±è´¹ä¸€ç‚¹é¢å¤–æ—¶é—´ï¼Œä¸ºæ•´ä¸ªç½‘ç»œçš„æ¯ä¸ªå·ç§¯å±‚æœç´¢æœ€é€‚åˆå®ƒçš„å·ç§¯å®ç°ç®—æ³•ï¼Œè¿›è€Œå®ç°ç½‘ç»œçš„åŠ é€Ÿã€‚

é€‚ç”¨åœºæ™¯æ˜¯**ç½‘ç»œç»“æ„å›ºå®šï¼ˆä¸æ˜¯åŠ¨æ€å˜åŒ–çš„ï¼‰ï¼Œç½‘ç»œçš„è¾“å…¥å½¢çŠ¶ï¼ˆåŒ…æ‹¬ batch sizeï¼Œå›¾ç‰‡å¤§å°ï¼Œè¾“å…¥çš„é€šé“ï¼‰æ˜¯ä¸å˜çš„**ï¼Œå…¶å®ä¹Ÿå°±æ˜¯ä¸€èˆ¬æƒ…å†µä¸‹éƒ½æ¯”è¾ƒé€‚ç”¨ã€‚

åä¹‹ï¼Œå¦‚æœå·ç§¯å±‚çš„è®¾ç½®ä¸€ç›´å˜åŒ–ï¼Œå°†ä¼šå¯¼è‡´ç¨‹åºä¸åœåœ°åšä¼˜åŒ–ï¼Œåè€Œä¼šè€—è´¹æ›´å¤šçš„æ—¶é—´ã€‚

```python
if args.use_gpu and torch.cuda.is_available():
    device = torch.device('cuda')
    torch.backends.cudnn.benchmark = True # ä¸€èˆ¬åŠ åœ¨å¼€å¤´
else:
    device = torch.device('cpu')
```

[å‚è€ƒ:çŸ¥ä¹](https://zhuanlan.zhihu.com/p/73711222)

### print åŠ¨æ€æ‰“å° ğŸ–¨ï¸

å®ç°åŸåœ°è¾“å‡ºåŠ¨æ€è¿›åº¦ã€‚

```python
import time
for i in range(50):
    print("Loading" + "."*i, end="\r")
    time.sleep(0.1)
print("")
```

### PyTorch model.train() â›¹â€â™‚ï¸

```python
model.train():
# åœ¨ä½¿ç”¨pytorchæ„å»ºç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ä¼šåœ¨ç¨‹åºä¸Šæ–¹æ·»åŠ ä¸€å¥model.train()ï¼Œä½œç”¨æ˜¯å¯ç”¨batch normalizationå’Œdrop outã€‚
model.eval():
# æµ‹è¯•è¿‡ç¨‹ä¸­ä¼šä½¿ç”¨model.eval()ï¼Œè¿™æ—¶ç¥ç»ç½‘ç»œä¼šæ²¿ç”¨batch normalizationçš„å€¼ï¼Œå¹¶ä¸ä½¿ç”¨drop outã€‚
```

### assert æ–­è¨€ â“ï¸

è¿˜ä¸ä¼š

### YAMLæ–‡ä»¶çš„è¯»å†™ ğŸ“„

è¿˜ä¸ä¼š

<!-- 
**Required**:
Check out [frontmatter](config/front-matter) for more details.
1. [Writing the summary manually in frontmatter](./front-matter.md#summary)
:::warning
However, it's still a convenient tool to help you scaffold out a new project with a set of predefined templates.
::: -->

### Pytorch .pth ä¿å­˜æ•°æ® ğŸ’¾

```python
i=1
for ... :
  if i == 1 :
      x_save_pt = out_resize_tensor #torch.from_numpy(out_display_img1).unsqueeze(0)
      y_save_pt = test_labels
  else :
      x_save_pt = torch.cat([x_save_pt, out_resize_tensor], dim=0) #x_save_pt = torch.cat([x_save_pt, torch.from_numpy(out_display_img1).unsqueeze(0)], dim=0)
      y_save_pt = torch.cat([y_save_pt, test_labels], dim=0)
  i = i+1

torch.save({'data': x_save_pt, 'target': y_save_pt}, "./12_googlenet_" + Atk_Type + ".pt")
```

### Pytorch æ•°æ®ä¹‹é—´è½¬æ¢ ğŸ”Œ

**1. PIL, Numpy to Tensor**

```python
import torchvision.transforms as transforms
x_Tensor = transforms.ToTensor()(x_PIL).unsqueeze(0)
x_Tensor = transforms.ToTensor()(x_Numpy).unsqueeze(0)
```

**2. Tensor to PIL**

```python
import torchvision.transforms as transforms

unloader = transforms.ToPILImage()

def trans_image(tensor):
    image = tensor.cpu().clone()
    image = image.squeeze(0)
    image = unloader(image)
    image = image.resize((299, 299), Image.ANTIALIAS) # ç¼©æ”¾
    return image

x_PIL = trans_image(x_Tensor)
```

**3. PIL to Numpy**

```python
x_Numpy = numpy.array(x_PIL, dtype = numpy.float32) # æ•°æ®ç±»å‹
```

### Pytorch Tensoræ•°æ®ç»´åº¦äº¤æ¢ â›—

```python
b = a.permute(0, 3, 1, 2)
```

### Shell è„šæœ¬ ğŸ—”

```bash
for TYPE in clean adv
do
    echo  "TYPE:  ${TYPE}"
    python googlenet.py --data_test Demo --scale 2 --pre_train download --test_only --save_results --type ${TYPE}
    python eval_googlenet.py --atk-type ${TYPE} --test-batch-size 64  --date 20220316
done
```

### Shell è„šæœ¬-å¸¦è¿è¡Œæ—¶é—´è®°å½• ğŸ—”ğŸ•¡ï¸

```bash
starttime=`date +'%Y-%m-%d %H:%M:%S'`
echo "Shell_Start_Time :            "$starttime

#sleep 1m
#sleep 1s

endtime=`date +'%Y-%m-%d %H:%M:%S'`
echo "Shell_End_Time :              "$endtime
time1=$(($(date +%s -d "$endtime") - $(date +%s -d "$starttime")));
echo " "
echo "Total_Shell_Time :            "   $(($time1/60/60/24)) "days  " $(($time1/60/60)) "hours  " $(($time1/60)) "minutes  " $(($time1%60)) "seconds"
echo " "
```

### Normalizationçš„æ‰°åŠ¨æ±‚è§£Torchä¿å­˜ â–

```python
import torch

unloader = transforms.ToPILImage()

perturb = (img_fgm - img)
p_min = torch.min(perturb)
p_max = torch.max(perturb)
normal_p = (perturb + p_min) / (p_max - p_min)
normal_p = torch.squeeze(normal_p, dim=0)
normal_p = unloader(normal_p)
name = 'adv_perturb.bmp'
normal_p.save('./fgsm_test/' + name)
```

### MarkDown å†™ç›®å½•ï¼Œå¸¦è·³è½¬ â†ªï¸

ä¸èƒ½å¸¦ç©ºæ ¼

```markdown
# ç›®å½•

- [è®ºæ–‡è§£è¯»](#è®ºæ–‡è§£è¯»)
  - [III. é˜²å¾¡æ¨¡å‹](#III_é˜²å¾¡æ¨¡å‹)
    - [A. Image Reconstruction Network](#A_Image_Reconstruction_Network)
      - [æ®‹å·®å—](#æ®‹å·®å—)
      - [éšæœºåŒ–å±‚](#éšæœºåŒ–å±‚)
    - [B. Perceptual Loss](#B_Perceptual_Loss)
  - [IV. å®éªŒ](#IV_å®éªŒ)
    - [A. Preparation](#A_Preparation)
      - [ç›®æ ‡æ¨¡å‹](#ç›®æ ‡æ¨¡å‹)
      - [æ”»å‡»æ–¹æ³•](#æ”»å‡»æ–¹æ³•)
      - [æ•°æ®é›†](#æ•°æ®é›†)
      - [å®æ–½ç»†èŠ‚](#å®æ–½ç»†èŠ‚)
- [ä»£ç è¿è¡Œ](#ä»£ç è¿è¡Œ)
  - [è¿›å…¥ç›®å½•](#è¿›å…¥ç›®å½•)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)
```

### pdbè°ƒè¯•å™¨ ğŸ‘¨ğŸ»â€ğŸ’»

- ENTER (é‡å¤ä¸Šæ¬¡å‘½ä»¤)
- c (ç»§ç»­)
- l (æŸ¥æ‰¾å½“å‰ä½äºå“ªé‡Œ)
- s (è¿›å…¥å­ç¨‹åº,å¦‚æœå½“å‰æœ‰ä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼Œé‚£ä¹ˆ s ä¼šè¿›å…¥è¢«è°ƒç”¨çš„å‡½æ•°ä½“)
- n(ext) è®©ç¨‹åºè¿è¡Œä¸‹ä¸€è¡Œï¼Œå¦‚æœå½“å‰è¯­å¥æœ‰ä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼Œç”¨ n æ˜¯ä¸ä¼šè¿›å…¥è¢«è°ƒç”¨çš„å‡½æ•°ä½“ä¸­çš„
- r (è¿è¡Œç›´åˆ°å­ç¨‹åºç»“æŸ)
- !<python å‘½ä»¤>
- h (å¸®åŠ©)
- a(rgs) æ‰“å°å½“å‰å‡½æ•°çš„å‚æ•°
- j(ump) è®©ç¨‹åºè·³è½¬åˆ°æŒ‡å®šçš„è¡Œæ•°
- l(ist) å¯ä»¥åˆ—å‡ºå½“å‰å°†è¦è¿è¡Œçš„ä»£ç å—
- p(rint) æœ€æœ‰ç”¨çš„å‘½ä»¤ä¹‹ä¸€ï¼Œæ‰“å°æŸä¸ªå˜é‡
- q(uit) é€€å‡ºè°ƒè¯•
- r(eturn) ç»§ç»­æ‰§è¡Œï¼Œç›´åˆ°å‡½æ•°ä½“è¿”å›

```python
import pdb

pdb.set_trace()
```

### PyTorch-N_DataLoader-åŒåºè®­ç»ƒ âœŒï¸

- è¯»å–DataLoader, è®¾å®šgenerator

```python
def data_loader_folder(samples_dir: str,
                       b_s: int = 1,
                       shuffle_bi: bool = False,
                       n_workers: int = 0,
                       ran_num: int = 1) -> Data.DataLoader:
    data_transform = transforms.Compose([
        ......
        transforms.ToTensor()
    ])
    train_data = Datasets.ImageFolder(root=samples_dir, 
                                      transform=data_transform)
    g = torch.Generator()
    g.manual_seed(ran_num)
    train_data_loader = Data.DataLoader(train_data, 
                                        batch_size=b_s, 
                                        shuffle=shuffle_bi,
                                        num_workers=n_workers, 
                                        generator=g)
    return train_data_loader
```

- æ¯ä¸ªepochï¼Œäº§ç”Ÿä¸åŒéšæœºæ•°ï¼Œä¼ ç»™DataLoaderä¸­çš„generator

```python
def data_loader_hook(dir2, dir3, batch_size1, epoch):
    rdx = random.randint(1, 100)
    loaders1 = data_loader_folder(dir2, 
                                  b_s=batch_size1, 
                                  shuffle_bi=True, 
                                  n_workers=1, 
                                  ran_num=rdx)
    loaders2 = data_loader_folder(dir3, 
                                  b_s=batch_size1, 
                                  shuffle_bi=True, 
                                  n_workers=1, 
                                  ran_num=rdx)
    return loaders1, loaders2
```

- N_DataLoaderè®­ç»ƒ-zip-zip(*)è¯»å–

```python
for epoch in range(start_epoch, end_epoch):
    data_loader1, data_loader2 = data_loader_hook(dir4, 
                                                  dir5, 
                                                  batch_size1, 
                                                  epoch)
    model.train()
    for num_batches, data_fuse in enumerate(zip(data_loader1, data_loader2)):
        load_img, load_lab = zip(*data_fuse)
        images_adv, images_clean = load_img
        target_adv, target_clean = load_lab
```

### cmdå®æ—¶åˆ·æ–°è¡Œå†…å®¹ ğŸ–¥ï¸
è€ƒè™‘ä»¥ä¸‹ç®€å•çš„Pythonè„šæœ¬ï¼š
```python
import time
import sys
for i in range(5):
  print(i),
  #sys.stdout.flush()
  time.sleep(1)
```
è¿™æ˜¯ä¸ºäº†æ‰“å°æ¯ç§’äº”ç§’é’Ÿä¸€ä¸ªå·ç ï¼Œä½ è¦æ˜¯è·‘ä¸è¿‡å®ƒï¼Œå› ä¸ºå®ƒæ˜¯ç°åœ¨ï¼ˆå–å†³äºé»˜è®¤çš„ç³»ç»Ÿç¼“å­˜ï¼‰ï¼Œä½ å¯èƒ½çœ‹ä¸åˆ°ä»»ä½•è¾“å‡ºï¼Œç›´åˆ°è„šæœ¬å®Œæˆï¼Œç„¶åä¸€ä¸‹å­ä½ ä¼šçœ‹åˆ°0 1 2 3 4å°åˆ°å±å¹•ã€‚è¿™æ˜¯å› ä¸ºè¾“å‡ºæ­£åœ¨ç¼“å†²ä¸­ï¼Œé™¤ésys.stdoutæ¯æ¬¡åˆ·æ–°åprintæ‚¨éƒ½ä¸ä¼šç«‹å³çœ‹åˆ°è¾“å‡ºã€‚ä»sys.stdout.flush()è¡Œä¸­åˆ é™¤æ³¨é‡Šä»¥æŸ¥çœ‹åŒºåˆ«ã€‚

```python
import sys
import time
# åœ¨åŒä¸€è¡Œåˆ·æ–° Print()
sys.stdout.write('\r')
sys.stdout.write('| Type [%s] : Acc:%f \t\t' %(at_tp, acc))
sys.stdout.flush()
print(time.time()) # åŠ è¿™ä¸€è¡Œå°±ä¼šä¸€è¡Œä¸€è¡Œæ¥ç€åˆ·æ–°
        
# è®­ç»ƒæ—¶å®æ—¶æ˜¾ç¤ºæ¯ä¸ªepoch,iter,lossçš„ç»Ÿè®¡æ•°æ®
sys.stdout.write('\r')
sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d] : Loss:%f \t\t'
        %(epoch, MAX_EPOCHS, counter,
            (train_size/TRAIN_BATCH_SIZE),cost.data.cpu().numpy()))
end=time.time()
print('Epoch:',epoch,' Time taken:',(end-start))
```

### Excel è¡Œåˆ—å˜é‡å–å€¼èµ‹å€¼ï¼ˆç”¨æ¥å¤„ç†å®éªŒæ•°æ®ï¼‰ğŸ“Š

```xls
=INDIRECT(ADDRESS((ROW()*2+1),10))

=INDIRECT(ADDRESS(ROW(),COLUMN()))
```


### å›ºå®šç§å­å®éªŒ ğŸŒ±
```python
import os
import argparse
import torch
import numpy as np
import random

parser = argparse.ArgumentParser()
parser.add_argument("--seed", type=int, default=0)
args = parser.parse_args()

def seed_torch(seed=2018):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

SEED=args.seed
seed_torch(seed=SEED)
```
## æœ€å ğŸ”š

é¡ºé¡ºåˆ©åˆ©ï¼Œå¤šå­¦å¤šç”¨ã€‚
<!-- Now, Check out your blog at `localhost:8080`, if everything is ok, you might be interested in the following topics:

- Configure this theme: We'll discuss in [the next section](../config) -->
